# About Me
虚步, a PhD student at BUPT. I am very fortunate to be advised by my advisor. My research is in the area of Vision, Language and Reasoning, with a focus on Visual Dialogue. In particular, I am interested in building a visually-grounded conversational AI (social robot) that can see the world and talk with us in natural language. Other interests include Visual/Language Grounding, Visual Reasoning, Visual Question Generation and Visually-grounded Referring Expression.

Now I'm researching GuessWhich and Visual Dialog(VisDial), please feel free to contact me with pangweitf@bupt.edu.cn or pangweitf@163.com if you have any questions or concerns.

# GuessWhat?! Game

GuessWhat?! is an image object-guessing game between two players. It has attracted considerable research interest in recent years.

Tensorflow implementation of the paper:<br>
Visual Dialogue State Tracking for Question Generation<br>
Wei Pang, Xiaojie Wang<br>
https://arxiv.org/abs/1911.07928<br>
AAAI 2020 (Oral)<br>

# Latest Progress on the GuessWhat?! Game
![](guesser_201911_10.png)



|Guesser | QGen | Max Q's | NewObject_S | G | BS | NewGame_S | G | BS|
| ------ | :----:  | :----: || :----: || :----: || :----: || :----: || :----: || :----: |
|guesser[20] | qgen[20] | 5  |41.6| 43.5| 47.1| 39.2| 40.8 |44.6|
|guesser(MN)[27]|TPG[27]|8   |- |48.77| -| -| -| -|

 表格      | 第一列     | 第二列     
 -------- | :-----------:  | :-----------: 
 第一行     | 第一列     | 第二列


arXiv: https://arxiv.org/abs/2002.10340

As shown in the uploaded figure "guesser_201911_10.png", our latest progress on GuessWhat?! game, it achieves near-perfect accuracy of 83.3% and outperforms all the previous methods. Notes that the human-level performance is 84.4%.

<b>This research was started in Mar. 2019 and ended in Nov. 2019.</b>

<b>If you use the experimental codes, please contact me with pangweitf@bupt.edu.cn or pangweitf@163.com.</b>


# Reference

If you use our code or models in your research, please cite with:

@InProceedings{pang2020guesswhat,<br>
  title={Visual Dialogue State Tracking for Question Generation},<br>
  author={Wei Pang and Xiaojie Wang},<br>
  booktitle={Proceedings of the Thirty-Fourth AAAI Conference on Artificial Intelligence (AAAI)},<br>
  year={2020}<br>
}<br>
@article{pw2020Guesser,<br>
  title={Guessing State Tracking for Visual Dialogue},<br>
  author={Wei Pang and Xiaojie Wang},<br>
  booktitle={arXiv:2002.10340},<br>
  year={2020}<br>
}<br>

	

# Current Vision-and-Language-and-Reasoning tasks, focuses on Visual Dialogue
1. Multimodal Dialogs(MMD), AAAI 2018<br>
2. CoDraw, ACL 2019<br>
3. GuessWhich, AAAI 2017<br>
4. Multi-agent GuessWhich, AAMAS 2019<br>
5. GuessWhat?!, CVPR 2017<br>
6. EmbodiedQA, CVPR 2018<br>
7. VideoNavQA, BMVC 2019<br>
8. GuessNumber, SLT 2018<br>
9. VisDial, CVPR 2017<br>
10. Image-Grounded Conversations(IGC), CVPR 2017<br>
11. VDQG, ICCV 2017<br>
12. RDG-Image guessing game, LREC 2014<br>
13. Deal or No Deal, CoRR 2017<br>
14. Video-Grounded Dialogue Systems (VGDS), ACL 2019<br>
15. Vision-Language Navigation (VLN), CVPR 2018<br>
16. Image Captioning<br>
17. Image Retrieval<br>
18. Visually-grounded Referring Expressions<br>
19. Multi-modal Verification, ACL 2019<br>
20. Viual Dialog based Referring Expression<br>
21. VQA<br>

